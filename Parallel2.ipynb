{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "import threading as th\n",
    "import gym\n",
    "import envs\n",
    "import random\n",
    "from torch.multiprocessing import Queue, Lock\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Transitions():\n",
    "#     def __init__(self, size=0):\n",
    "#         self.size = size\n",
    "#         self._data = []\n",
    "        \n",
    "#     def merge(self, item):\n",
    "#         if isinstance(item[0], tuple):\n",
    "#             return (self.merge(i) for i in item)\n",
    "#         elif isinstance(item[0], torch.Tensor):\n",
    "#             return torch.cat(item, axis=0)\n",
    "#         else:\n",
    "#             return item\n",
    "    \n",
    "#     @property\n",
    "#     def collated(self):\n",
    "#         values = map(self.merge, zip(*[transition._asdict().values()\n",
    "#                                        for transition in self]))\n",
    "        \n",
    "#         return BatchedTransitions(*values)\n",
    "    \n",
    "#     def sample(self, n_items):\n",
    "#          return Transitions().extend(\n",
    "#             random.choices(self._data, k=n_items)\n",
    "#         )\n",
    "    \n",
    "#     def push(self, transition):\n",
    "#         self._data.append(transition)\n",
    "        \n",
    "#         if self.size != 0 and len(self._data) > self.size:\n",
    "#             self._data.pop(0)\n",
    "            \n",
    "#     def extend(self, arr):\n",
    "#         self._data += arr\n",
    "#         return self\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self._data)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         self._idx = -1\n",
    "#         return self\n",
    "\n",
    "#     def __next__(self):\n",
    "#         self._idx += 1\n",
    "        \n",
    "#         if self._idx < len(self._data):\n",
    "#             return self._data[self._idx]\n",
    "        \n",
    "#         raise StopIteration\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition = namedtuple('Transition', ['state', 'next_state', 'objective', 'reward', 'done'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchedTransitionsBase = namedtuple('BatchedTransition', ['state', 'next_state', 'objective', 'reward', 'done'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BatchedTransitions(BatchedTransitionsBase):\n",
    "#     def __new__(cls, *args):\n",
    "#         self = super(BatchedTransitions, cls).__new__(cls, *args)\n",
    "#         return self\n",
    "    \n",
    "#     def pf(self, item):\n",
    "#         if isinstance(item, torch.Tensor):\n",
    "#             return item.pin_memory()\n",
    "#         elif isinstance(item, tuple):\n",
    "#             return tuple(self.pf(i) for i in item)\n",
    "#         else:\n",
    "#             return item\n",
    "    \n",
    "#     def prefetch(self):\n",
    "#         return BatchedTransitions(*map(self.pf, self._asdict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSamplerStatus(Enum):\n",
    "    READY = 1\n",
    "    WAITING_TO_SAMPLE = 2\n",
    "    SAMPLING = 3\n",
    "\n",
    "class BatchSamplerInitiatorThread(th.Thread):\n",
    "    def __init__(self, bs):\n",
    "        super(BatchSamplerInitiatorThread, self).__init__()\n",
    "        self.bs = bs\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if len(self.bs.batches) + self.bs.n_batches_sampling < 10:\n",
    "                prop = [random.random() for _ in self.bs.explorers]\n",
    "                prop = [int(p / sum(prop) * self.bs.BATCH_SIZE) for p in prop]\n",
    "                prop[-1] = self.bs.BATCH_SIZE - sum(prop[:-1])\n",
    "                \n",
    "                for idx, (p, explorer) in enumerate(zip(prop, self.bs.explorers)):\n",
    "                    if p > 0: explorer.instruction_queue.put((self.bs.current_sampler, p))\n",
    "                    print(f'[INFO] Assigning Explorer {idx} to sample {p} transitions for batch {self.bs.current_sampler}')\n",
    "\n",
    "\n",
    "                self.bs.n_batches_sampling += 1\n",
    "                self.bs.current_sampler += 1\n",
    "                self.bs.current_sampler %= self.bs.PREFETCH_BUFFER\n",
    "                \n",
    "#             for i in range(self.bs.PREFETCH_BUFFER):\n",
    "#                 if self.bs.batch_status[i] != BatchSamplerStatus.WAITING_TO_SAMPLE:\n",
    "#                     continue\n",
    "\n",
    "#                 self.bs.batch_status[i] = BatchSamplerStatus.SAMPLING\n",
    "\n",
    "#                 prop = [random.random() for _ in self.bs.explorers]\n",
    "#                 prop = [int(p / sum(prop) * self.bs.BATCH_SIZE) for p in prop]\n",
    "#                 prop[-1] = self.bs.BATCH_SIZE - sum(prop[:-1])\n",
    "                \n",
    "#                 for idx, (p, explorer) in enumerate(zip(prop, self.bs.explorers)):\n",
    "#                     if p > 0: explorer.instruction_queue.put((i, p))\n",
    "#                     print(f'[INFO] Assigning Explorer {idx} to sample {p} transitions for batch {i}')\n",
    "                    \n",
    "class BatchSamplerAssignmentThread(th.Thread):\n",
    "    def __init__(self, bs):\n",
    "        super(BatchSamplerAssignmentThread, self).__init__()\n",
    "        self.bs = bs\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if not self.bs.int_queue.empty():\n",
    "                print(f'[INFO] Aggregator received new batch')\n",
    "                batch_id, batch = self.bs.int_queue.get()\n",
    "              \n",
    "                self.bs.batches.append(batch)\n",
    "                self.bs.n_batches_sampling -= 1\n",
    "\n",
    "#                 self.bs.batches[batch_id] = batch\n",
    "#                 self.bs.batch_status[batch_id] = BatchSamplerStatus.READY\n",
    "#                 print(f'[INFO] Batch {batch_id} ready.')\n",
    "                \n",
    "            time.sleep(1)\n",
    "                    \n",
    "class BatchSamplerProcessingProcess(mp.Process):\n",
    "    def __init__(self, batch_size, in_queue, out_queue, prefetch):\n",
    "        super(BatchSamplerProcessingProcess, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.transitions = []\n",
    "        \n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        \n",
    "        self.prefetch = prefetch\n",
    "        self.n_transitions = 0\n",
    "        \n",
    "    def merge(self, item, prefetch=False):\n",
    "        if len(item) == 1:\n",
    "            return item[0]\n",
    "    \n",
    "        if isinstance(item[0], tuple):\n",
    "            return tuple(self.merge(i, prefetch=prefetch) for i in zip(*item))\n",
    "        elif isinstance(item[0], torch.Tensor):\n",
    "            if prefetch:\n",
    "                return torch.cat(item, axis=0).pin_memory()\n",
    "            else:\n",
    "                return torch.cat(item, axis=0)\n",
    "        elif isinstance(item[0], list):\n",
    "            return list(reduce(add, item))\n",
    "        else:\n",
    "            return list(item)\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if not self.in_queue.empty():\n",
    "                batch_id, data = self.in_queue.get()\n",
    "                \n",
    "                self.transitions.append(data)\n",
    "                self.n_transitions += len(data[-1])\n",
    "                \n",
    "                print(f'[INFO] Batch {batch_id} received new data {self.n_transitions}')\n",
    "\n",
    "                if self.n_transitions == self.batch_size:\n",
    "                    batch = self.merge(self.transitions, prefetch=self.prefetch)\n",
    "                    self.out_queue.put((batch_id, batch))\n",
    "\n",
    "                    self.transitions = []\n",
    "                    self.n_transitions = 0\n",
    "        \n",
    "class BatchSampler:\n",
    "    PREFETCH_BUFFER = 10\n",
    "    BATCH_SIZE = 64\n",
    "    \n",
    "    def __init__(self, explorers, exp2bs_queues, prefetch=True):\n",
    "        self.explorers = explorers\n",
    "        self.current = 0\n",
    "        self.exp2bs_queues = exp2bs_queues\n",
    "        self.int_queue = Queue()\n",
    "        \n",
    "        self.prefetch = prefetch\n",
    "        \n",
    "#         self.batches = [[] for _ in range(self.PREFETCH_BUFFER)]\n",
    "        self.batches = collections.deque()\n",
    "        self.batch_status = [\n",
    "            BatchSamplerStatus.WAITING_TO_SAMPLE\n",
    "            for _ in range(self.PREFETCH_BUFFER)\n",
    "        ]\n",
    "        self.n_batches_sampling = 0\n",
    "        self.current_sampler = 0\n",
    "        \n",
    "        # Thread to monitor sampling progress\n",
    "        for batch_id in range(self.PREFETCH_BUFFER):\n",
    "            BatchSamplerProcessingProcess(\n",
    "                self.BATCH_SIZE, self.exp2bs_queues[batch_id], self.int_queue, self.prefetch\n",
    "            ).start()\n",
    "        \n",
    "        BatchSamplerAssignmentThread(self).start()\n",
    "        \n",
    "        # Thread to initiate sampling\n",
    "        BatchSamplerInitiatorThread(self).start()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.current = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        while len(self.batches) == 0:\n",
    "            pass\n",
    "        \n",
    "        return self.batches.popleft()\n",
    "#         while self.batch_status[self.current] != BatchSamplerStatus.READY:\n",
    "#             pass\n",
    "        \n",
    "#         batch = self.batches[self.current]\n",
    "        \n",
    "#         self.batches[self.current] = []\n",
    "#         self.batch_status[self.current] = BatchSamplerStatus.WAITING_TO_SAMPLE\n",
    "        \n",
    "#         self.current += 1\n",
    "#         self.current %= self.PREFETCH_BUFFER\n",
    "        \n",
    "#         return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplorerIOThread(th.Thread):\n",
    "    def __init__(self, process):\n",
    "        super(ExplorerIOThread, self).__init__()\n",
    "        \n",
    "        self.process = process\n",
    "        \n",
    "    def merge(self, item, prefetch=False):\n",
    "        if len(item) == 1:\n",
    "            return item[0]\n",
    "    \n",
    "        if isinstance(item[0], tuple):\n",
    "            return tuple(self.merge(i, prefetch=prefetch) for i in zip(*item))\n",
    "        elif isinstance(item[0], torch.Tensor):\n",
    "            if prefetch:\n",
    "                return torch.cat(item, axis=0).pin_memory()\n",
    "            else:\n",
    "                return torch.cat(item, axis=0)\n",
    "        elif isinstance(item[0], list):\n",
    "            return list(reduce(add, item))\n",
    "        else:\n",
    "            return list(item)\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if not self.process.instruction_queue.empty():\n",
    "                ins = self.process.instruction_queue.get()\n",
    "                \n",
    "                if ins is None:\n",
    "                    print(f'[INFO] Process {self.process.idx} - thread: Joining...')        \n",
    "                    self.process.stop = True\n",
    "\n",
    "                    break\n",
    "                    \n",
    "                batch_id, n_items = ins\n",
    "                    \n",
    "                sampled = random.choices(self.process.transitions, k=n_items)\n",
    "                self.process.result_queue[batch_id].put((batch_id, self.merge(sampled)))\n",
    "                print(f'[INFO] Process {self.process.idx}: Sampled {n_items} transitions')        \n",
    "\n",
    "class ExplorerProcess(mp.Process):\n",
    "    def __init__(self, instruction_queue, result_queue, idx, env_name, **kwargs):\n",
    "        super(ExplorerProcess, self).__init__()\n",
    "        \n",
    "        self.instruction_queue = instruction_queue\n",
    "        self.result_queue = result_queue\n",
    "        \n",
    "        self.env = gym.make('StopSkip-v1', **kwargs)\n",
    "        self.env.reset()\n",
    "        \n",
    "        self.idx = idx\n",
    "        self.transitions = []\n",
    "        \n",
    "        self.stop = False\n",
    "        \n",
    "    def run(self):\n",
    "        print(f'[INFO] Process {self.idx}: {id(self.transitions)}')\n",
    "        ExplorerIOThread(self).start()\n",
    "              \n",
    "        j = 1\n",
    "        \n",
    "        s = self.env._obs()\n",
    "        while not self.stop:\n",
    "            action = self.env.action_space.sample()\n",
    "            ns, o, r, d = self.env.step(action)\n",
    "            \n",
    "            self.transitions.append((s, ns, o, r, d))\n",
    "                                              \n",
    "            s = ns\n",
    "            \n",
    "            if len(self.transitions) > 100:\n",
    "                self.transitions.pop(0)\n",
    "            \n",
    "            if j % 10 == 0:\n",
    "                print(f'[INFO] Process {self.idx}: {len(self.transitions)} transitions')\n",
    "                j = 0\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "        print(f'[INFO] Process {self.idx}: Joining...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Process 0: 139849177679232\n",
      "[INFO] Process 0: 10 transitions\n",
      "[INFO] Process 0: 20 transitions\n",
      "[INFO] Process 0: 30 transitions\n",
      "[INFO] Process 0: 40 transitions\n",
      "[INFO] Process 0: 50 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 60 transitions\n",
      "[INFO] Process 0: 70 transitions\n",
      "[INFO] Process 0: 80 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 90 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: Sampled 64 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n",
      "[INFO] Process 0: 100 transitions\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_PROCESSES = 1\n",
    "PREFETCH_BUFFER = 20\n",
    "explorers = []\n",
    "bs2exp_queues = []\n",
    "exp2bs_queue = [Queue() for _ in range(PREFETCH_BUFFER)]\n",
    "\n",
    "for i in range(0, NUMBER_OF_PROCESSES):\n",
    "    bs2exp_queues.append(Queue())\n",
    "\n",
    "    p = ExplorerProcess(\n",
    "        instruction_queue=bs2exp_queues[-1],\n",
    "        result_queue=exp2bs_queue,\n",
    "        idx=i,\n",
    "        env_name='StopSkip-v1'\n",
    "    )\n",
    "    \n",
    "    p.start()\n",
    "    explorers.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Batch 0 received new data 64\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 0\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 1\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 2\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 3\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 4\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 5\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 6\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 7\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 8\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 9\n",
      "[INFO] Batch 1 received new data 64\n",
      "[INFO] Batch 2 received new data 64\n",
      "[INFO] Batch 3 received new data 64\n",
      "[INFO] Batch 4 received new data 64\n",
      "[INFO] Batch 5 received new data 64\n",
      "[INFO] Batch 6 received new data 64\n",
      "[INFO] Batch 7 received new data 64\n",
      "[INFO] Batch 8 received new data 64\n",
      "[INFO] Batch 9 received new data 64\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Batch 0 received new data 64\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 0\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Batch 1 received new data 64\n",
      "[INFO] Batch 2 received new data 64\n",
      "[INFO] Batch 3 received new data 64\n",
      "[INFO] Batch 4 received new data 64[INFO] Batch 5 received new data 64\n",
      "\n",
      "[INFO] Batch 6 received new data 64\n",
      "[INFO] Batch 7 received new data 64\n",
      "[INFO] Batch 8 received new data 64\n",
      "[INFO] Batch 9 received new data 64[INFO] Batch 0 received new data 64\n",
      "\n",
      "[INFO] Batch 1 received new data 64\n",
      "[INFO] Batch 2 received new data 64\n",
      "[INFO] Batch 3 received new data 64\n",
      "[INFO] Batch 4 received new data 64\n",
      "[INFO] Batch 5 received new data 64\n",
      "[INFO] Batch 6 received new data 64\n",
      "[INFO] Batch 7 received new data 64\n",
      "[INFO] Batch 8 received new data 64\n",
      "[INFO] Batch 9 received new data 64\n",
      "[INFO] Batch 0 received new data 64\n",
      "[INFO] Batch 1 received new data 64\n",
      "[INFO] Batch 2 received new data 64\n",
      "[INFO] Batch 3 received new data 64\n",
      "[INFO] Batch 4 received new data 64\n",
      "[INFO] Batch 5 received new data 64\n",
      "[INFO] Batch 6 received new data 64\n",
      "[INFO] Batch 7 received new data 64\n",
      "[INFO] Batch 8 received new data 64\n",
      "[INFO] Batch 9 received new data 64\n",
      "[INFO] Batch 0 received new data 64\n",
      "[INFO] Batch 1 received new data 64\n"
     ]
    }
   ],
   "source": [
    "bs = BatchSampler(explorers, exp2bs_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = next(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 1\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 2\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 3\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 4\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 5\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 6\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 7\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 8\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 9\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 0\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 1\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 2\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 3\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 4\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 5\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 6\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 7\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 8\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 9\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 0\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 1\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 2\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 3\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 4\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 5\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 6\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 7\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 8\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 9\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 0\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "n_batches = 0\n",
    "while time.time() - t < 30:\n",
    "    _ = next(bs)\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    n_batches += 1\n",
    "    \n",
    "t = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Aggregator received new batch\n",
      "0.97 BPM\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Assigning Explorer 0 to sample 64 transitions for batch 1\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n",
      "[INFO] Aggregator received new batch\n"
     ]
    }
   ],
   "source": [
    "bpm = n_batches / t\n",
    "print(f'{bpm:.2f} BPS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
